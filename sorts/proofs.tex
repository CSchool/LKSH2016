\documentclass[10pt,a4paper]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}

\usepackage[russian, english]{babel}

\usepackage{yfonts} % gothic fonts
\usepackage{color}
\usepackage{listings}

\usepackage{fancyhdr}

\pagestyle{headings}

\definecolor{cmntClr}{rgb}{0.1,0.5,0.2}
\definecolor{keyWClr}{rgb}{0.2,0.1,0.5}
\definecolor{emphClr}{rgb}{0.5,0.1,0.2}
\definecolor{bkgrndClr}{rgb}{0.95,0.95,0.95}

\newtheorem*{Cl}{Claim}
\newtheorem*{Def}{\textfrak{Def:}}
\renewcommand{\O}{\mathcal{O}}

\title{Сортировки}

\begin{document}

\maketitle

\lstset{
    language=C++,
    commentstyle=\color{cmntClr},
    keywordstyle=\color{keyWClr},
    emphstyle=\color{emphClr},
    basicstyle=\ttfamily,
    backgroundcolor=\color{bkgrndClr},
    frame=single
}

\section{Теорема о нижней оценке времени 
работы сортировки на произвольном входе}

\begin{Cl}
Без дополнительной информации о значениях массива, число сравнений 
при сортировке не менее $n \log n$
\end{Cl}

\begin{proof}
Сортировка внутри себя делает некоторые сравнения, их результат
можно закодировать битовой строкой длины $k$, где $k$ --- число
сравнений. На вход нам даётся перестановка массива, всего их $n!$,
тогда получаем неравенство $2^k \geq n!$, т.к. иначе по принципу
Дирихле мы не сможем отличить две перестановки.

Теперь $2^k \geq n! \Rightarrow k \geq \log n! \sim n \log n \Rightarrow k = \Omega(n \log n)$
\end{proof}

\section{Binary heap}

Двоичная куча -- структура данных, реализующая интрефейс очереди с приоритетом.

Двоичная куча представляет собой двоичное дерево, где в вершинах
дерева лежат значения, так что значение родителя меньше или равно
значениям детей (тогда в вершине хранится глобальный минимум, если 
хотим максимум, то нужно поддерживать свойство другого неравенства).

Операции, которые мы можем реализовать:
\begin{itemize}
\item extract min
\item add
\item sift up
\item sift down
\end{itemize}

Все будут работать за глубину дерева, т.е. $\O(\log n)$

\subsection{Sift Down}

Заданную вершину мы обмениваем с минимумом/максимумом из детей,
пока нарушено свойство кучи.

\subsection{Sift Up}

Заданную вершину мы обмениваем с родителем пока нарушено свойство кучи.

\subsection{Add}

Подвешиваем к самой последней вершине и просеиваем вверх.

\subsection{Extract Min}

Вынимаем вершину и кладём туда нижнюю вершину и просеиваем вниз.

\begin{Cl}
Двоичную кучу можно построить за $\O(n)$
\end{Cl}

\begin{proof}
Сначала поймём как будет выполняться построение.

\begin{lstlisting}
for (int i = n; i > 0; --i) {
    siftDown(i);
}
\end{lstlisting}

Теперь про время, оценим так:

$$ Time = 
    \sum_{i=1}^n t_i = 
    \sum_{h = 1}^{\log n} h \cdot c_i = 
    \sum_{h = 1}^{\log n} h \cdot \frac{n}{2^h} = 
    n \cdot \underbrace{\sum_{h = 1}^{\log n} \frac{h}{2^h}}_{
    \parbox{2cm}{
        $\rightarrow const$ \\
        при $n \rightarrow \infty$
        }} \Longrightarrow Time = \O(n) $$

$h$ ---  это расстояние от низа кучи

$c_i$ --- это число элементов на одном 
расстоянии от низа кучи

$c_i = \frac{n}{2^h}$ --- $n \sim 2^H$, где $H$  высота кучи,
на уровне элементов $2^{H_i}$, где $H_i$ расстояние от вершины 
до уровня, тогда $2^{H-h} = \frac{n}{2^h}$

\end{proof}

\section{Heap sort}

\subsection{Естественный вариант сортировки}

\begin{enumerate}
\item строим кучу на массиве за $\O(n)$
\item вынимаем много раз минимум/максимум
\item итоговая ассимптотика $\O(n \log n)$
\end{enumerate}

\subsection{Модификация}

Мы хотим сейчас изменить сортировку так, чтобы на некоторых входных 
данных она работала быстрее.

Пусть у нас будет две кучи $H$ --- это куча из всех элементов и $C$ 
--- куча кандидатов (изначально состоит из одной вершины).

Теперь алгоритм:
\begin{enumerate}
\item вынимаем минимум $a$ из $C$
\item добавляем в $C$ детей $a$ из $H$
\end{enumerate}

Теперь, когда это будет работать быстрее. Если минимумы расположены в 
порякде обхода поиском в глубину, то окажется, что куча $C$ всегда 
будет содержать не более $\log n$ элементов (глубина кучи $H$), тогда 
время работы сортировки будет $\O(n \log \log n)$

\section{Merge sort}

Merge sort ---  это сортировка, которая работает за $\O(n \log n)$ 
времени и $\O(n)$ дополнительной памяти.

\subsection{Merge}

Merge --- это функция, принимающая два отсортированных массива и возращающая
отсортированный массив, состоящий из элементов исходных. Именно эта функция 
использует дополнительную память.

Как она работает:
\begin{enumerate}
\item поддерживаем указатели на текущий элемент в каждом массиве, изначально 
указывают, на первые элементы 
\item теперь пока какой-нибудь из массивов не опустеет выбираем минимум из
начальных элементов и ставим его в конец нового массива
\item из оставшегося непустого массива все копируем в конец нового.
\item в новом теперь лежит новый слитый массив
\end{enumerate}

\subsection{Sort}

\begin{enumerate}
\item если размер массива 2, то делаем swap если есть инверсия, если размер 
массива 1 -- то ничего.
\item в остальных случаях делаем рекурсивные вызовы сортировки обеих половин массива.
\item делаем merge отсортированных половинок.
\end{enumerate}

\section{Quick sort}

\subsection{Описание}

Сортировка которая в работает за рандомиированный $\O(n \log n)$.

Основная идея взять какой-нибуь элемент и поставить его на правильную позицию, 
а все остальные расположить правильно относительно позиции выбранного элемента.

Назовём эту операцю \lstinline|partition|, пример работы:
\begin{lstlisting}
int a[] = { 2, 3, 5, 2, 6, 9, 1, 2};
partition(a, 5);
// a[] = { 2, 3, 2, 1, 2, 5, 6, 9 }
\end{lstlisting}

Теперь сам алгоритм псевдокодом:

\begin{lstlisting}
qSort(a, len) {
    // base of recursion
    x = random_choice(a);
    t = partition(a, x);
    qSort(a, t);
    qSort(a + t + 1, len - t - 1);
}
\end{lstlisting}

\subsection{Оценка времени работы}

Для оценки времени работы нужно воспользоваться магией теории вероятности, 
нужно дать несколько определений.

\subsubsection{Ликбез по терверу}

\begin{Def}
$\Omega$ --- множество событий.
\end{Def}

\begin{Def}
$Pr\colon \Omega \rightarrow [0, 1]$ --- вероятностная функция.
\end{Def}

\begin{Def}
$\chi\colon \Omega \rightarrow \mathbb{R}$ --- случайная величина.
\end{Def}

\begin{Def}
$E( \chi ) = \sum\limits_{q \in \Omega} Pr(q) \chi(q)$ --- математическое 
ожидание случайной величины.
\end{Def}

\begin{Cl}[О монетке]
Математическое ожидание числа выпадений монетки подряд орлом вверх равно двум.
\end{Cl}

\begin{proof}
Определимся, что будет являться событиями: $\Omega$ --- множество выпадений 
монетки орлом вверх.

Теперь случайная величина: $\chi(q)$ --- число бросков монетки.

Теперь, пусть $q_k$ --- это событие, что $k$ раз подряд выпал орёл, тогда вероятность 
этого события можно посчитать по правилу произведения: $Pr(q_k) =~ \frac{1}{2^k}$

Теперь посчитаем мат. ождание 
\begin{gather*}
E(\chi) = 
\sum\limits_{k=0}^{\infty} \frac{k}{2^k} =
\frac{1}{2}\sum\frac{1}{2^k} +
\frac{1}{4}\sum\frac{1}{2^k} + 
\frac{1}{8}\sum\frac{1}{2^k} + \cdots = \\
\left(\sum\frac{1}{2^k}\right)
\left(\frac{1}{2} +
\frac{1}{4} + 
\frac{1}{8} + \cdots\right) = 2 \cdot \frac{1}{2} \cdot 2 = 2 \\
\end{gather*}

P.S.: на самом деле мы в тайне пользуемся абсолютной сходимостью данного ряда, 
т.к. переставляем его слагаемые.
\end{proof}

\subsubsection{Назад к оценке}

В первую очередь напишем рекурентное соотношение на время работы:
$$T(n) = T(x) + T(n - x) + \O(n)$$ 
Первые два слагаемые от рекурсивных вызовов и последнее от операции \lstinline|partition|.

\paragraph{Интуиция}

Пусть есть отсортированный массив. Поделим его на 3 части: с крайние части 
размера $1/4$ от длины массива. Будем считать что середина --- это хорошие 
элементы. Теперь, что плохого в быстрой сортировке? Плохо, если мы выбираем 
крайние элементы, т.к. тогда рекурента вырождается в следующую вещь: 
$$T(n) = T(n - c) + \O(n) \Rightarrow T(n) = n^2$$
Но мат. ожидание выбора плохих элементов подряд --- 2, значит большую часть 
времени мы будем выбирать хорошие элементы и рекурента будет хорошей.

\paragraph{Формализм}

Давайте посчитаем мат. ожидание времени работы ручками по индукции:

$$
E = 
\sum_x \frac{1}{n}\left(T(x) + T(n - x) + \O(n)\right) =
\frac{2}{n}\sum_{x=1}^{n - 1} T(x) + \O(n)
$$

Применим индукционное предположение:

\begin{gather*}
E = \frac{2}{n} \sum_{x=1}^{n - 1} \O(x\log x) + \O(n) = \\
\frac{2}{n} \sum_{x=1}^{n - 1} C \cdot x\log x + \O(n) \leq
\frac{2C}{n} \int^n_1 x \log x \ dx + \O(n) =
\O(n \log n)
\end{gather*}

Посчитанный определённый интеграл можно оценить как $\O(n \log n)$, который съедает 
лишнее $\O(n)$. Т. о. получили нужную оценку времени работы quick sort.

\section{Radix sort}

Пусть есть строки/числа. Тогда можно делать сортировку которая будет работать
следующим образом: будем сортировать числа/строки по самому младшему разряду,
используя стабильную сортировку. Можно использовать ранее упомянутую count sort,
тогда время работы такой процедуры будет $\O(nk)$, где $n$ число разрядов,
счисления, а $k$ --- кол-во чисел.

\section{Bucket sort}

\subsection{Алгоритм}

\begin{enumerate}
\item найдём границы диапазона
\item если границы равны, то ничего сортировать не нужно
\item разбрасываем элементы массива по группам:

$x_i$ помещаем в $\left\lceil\frac{x_i - \min}{\max - \min + 1} \cdot n \right\rceil$

\item теперь над каждой группой либо рекурсивно вызваться, либо совершить 
простую квадратичную сортировку
\end{enumerate}

Грубая оценка времени работы: $\O(n \log (max - min))$, т.к. поделимся хотя 
бы на две группы.

\subsection{Оценки времени для $\mathbb{N}$}

Группировать будем по ведущим битам. Тогда получается, что если мы пользуемся
только типами \lstinline|int| или \lstinline|long long|, то логарифм из предыдущей
оценки превращается в 32 или 64 и наша сортирка будет работать за $\O(n)$.

\end{document}